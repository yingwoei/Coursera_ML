## What I learned from Assignment 2
* How to compute logistic regression - cost function, gradient, and hypothesis.
* How lambda helps to regularize regression to reduce overfitting.
* Regularization is an algorithm that shrinks all parameters theta.
* theta(1) in octave is theta_0 in math because Ocatve indexing starts at 1.
* theat(1) = 0 to exclude the bias feature.
* Hypothesis in logistic regression measures the probability of one test case belong to Class 0/1.
